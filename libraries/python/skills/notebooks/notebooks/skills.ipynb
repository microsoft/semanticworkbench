{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skills\n",
    "\n",
    "Making \"recipes\" happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup\n",
    "\n",
    "Run this cell to set the notebook up. Other sections can be run independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import aio, DefaultAzureCredential, get_bearer_token_provider, AzureCliCredential\n",
    "\n",
    "from openai import AsyncAzureOpenAI, AzureOpenAI\n",
    "\n",
    "import logging \n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up structured logging to a file.\n",
    "class JsonFormatter(logging.Formatter):\n",
    "    def format(self, record) -> str:\n",
    "        record_dict = record.__dict__\n",
    "        log_record = {\n",
    "            'timestamp': self.formatTime(record, self.datefmt),\n",
    "            'level': record.levelname,\n",
    "            'session_id': record_dict.get('session_id', None),\n",
    "            'run_id': record_dict.get('run_id', None),\n",
    "            'message': record.getMessage(),\n",
    "            'data': record_dict.get('data', None),\n",
    "            'module': record.module,\n",
    "            'funcName': record.funcName,\n",
    "            'lineNumber': record.lineno,\n",
    "            'logger': record.name,\n",
    "        }\n",
    "        extra_fields = {\n",
    "            key: value for key, value in record.__dict__.items() \n",
    "            if key not in ['levelname', 'msg', 'args', 'exc_info', 'funcName', 'module', 'lineno', 'name', 'message', 'asctime', 'session_id', 'run_id', 'data']\n",
    "        }\n",
    "        log_record.update(extra_fields)\n",
    "        return json.dumps(log_record)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "modules = ['httpcore.connection', 'httpcore.http11', 'httpcore.sync.connection', 'httpx', 'openai', 'urllib3.connectionpool', 'urllib3.util.retry']\n",
    "for module in modules:\n",
    "    logging.getLogger(module).setLevel(logging.ERROR)\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "data_dir = Path('.data')\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir()\n",
    "handler = logging.FileHandler(data_dir / 'logs.jsonl')\n",
    "handler.setFormatter(JsonFormatter())\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv()\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "azure_openai_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\", \"\"),\n",
    "    \"api_version\": os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"\"),\n",
    "    \"max_retries\": 2,\n",
    "}\n",
    "\n",
    "model = azure_openai_config.get(\"azure_deployment\", \"gpt-4o\")\n",
    "\n",
    "async_client = AsyncAzureOpenAI(\n",
    "    **azure_openai_config,\n",
    "    azure_ad_token_provider=aio.get_bearer_token_provider(\n",
    "        aio.AzureCliCredential(),\n",
    "        \"https://cognitiveservices.azure.com/.default\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    **azure_openai_config,\n",
    "    azure_ad_token_provider=get_bearer_token_provider(\n",
    "        AzureCliCredential(),\n",
    "        \"https://cognitiveservices.azure.com/.default\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Assistants API (and the GPTs that are built with it) need more capabilities than just a few plugins. What we actually want to do is be able to introduce new capabilities not as \"tools\" but as \"skills\". A skill is like a tool in that it allows the agent to use various functions for generating chats, but also, we want the agent to be able to run multi-step routines and for skills to be able to interact with one another.\n",
    "\n",
    "Specifically, a `Skill` provides:\n",
    "\n",
    "- A nice way to package up a set of capabilities we can provide to an assistant.\n",
    "- A set of actions that can be made available directly to the assistant (functions) and to the user (commands).\n",
    "- A set of routines that can be executed by an assistant, potentially in cooperation with the user.\n",
    "\n",
    "Here is a \"Posix\" skill that is able to interact with the filesystem in a posix-style way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from posix_skill import PosixSkill\n",
    "from chat_driver import ChatDriverConfig\n",
    "from context import Context\n",
    "\n",
    "context = Context(\"skills-123.posix\")\n",
    "\n",
    "# Define the posix skill.\n",
    "chat_driver_config = ChatDriverConfig(\n",
    "    openai_client=async_client,\n",
    "    model=model,\n",
    "    instructions=\"You are an assistant that has access to a sand-boxed Posix shell.\",\n",
    "    context=context,\n",
    ")\n",
    "\n",
    "posix_skill = PosixSkill(\n",
    "    context=context,\n",
    "    sandbox_dir=Path(\".data\"),\n",
    "    chat_driver_config=chat_driver_config,\n",
    "    mount_dir=\"/mnt/data\",\n",
    ")\n",
    "\n",
    "# Registered actions can be called directly from the skill.\n",
    "await posix_skill.actions.touch(\"test.txt\")\n",
    "print(await posix_skill.actions.ls(\"\"))\n",
    "\n",
    "# Note: Look in the .data directory for the output from these actions!\n",
    "\n",
    "# Chat with the skill.\n",
    "while True:\n",
    "    message = input(\"User: \")\n",
    "    if message == \"\":\n",
    "        break\n",
    "    print(f\"User: {message}\", flush=True)\n",
    "    response = await posix_skill.respond(message)\n",
    "    print(f\"Posix skill: {response.message}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An assistant\n",
    "\n",
    "Finally, we have all the building blocks to create a more capable assistant from skills. Our `assistant` library allows you to register skills to an assistant enabling the assistant to perform actions and routines. Here is how simple it is to add our posix skill to an assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from skill_library import Assistant\n",
    "from chat_driver import ChatDriverConfig\n",
    "from posix_skill import PosixSkill\n",
    "\n",
    "\n",
    "# Define the assistant.\n",
    "instructions = \"You are a helpful assistant.\"\n",
    "\n",
    "chat_driver_config = ChatDriverConfig(\n",
    "    openai_client=async_client,\n",
    "    model=model,\n",
    "    instructions=instructions,\n",
    ")\n",
    "\n",
    "assistant = Assistant(name=\"Alice\", chat_driver_config=chat_driver_config, session_id=\"posix-assistant-123\")\n",
    "\n",
    "# Now that the assistant has been created with a context, we can create the\n",
    "# skills and register them with the assistant's context.\n",
    "\n",
    "# Define the posix skill. This skill will be used by the assistant. Note that\n",
    "# some skills may have a conversational interface using a chat driver.\n",
    "posix_skill = PosixSkill(\n",
    "    context=assistant.context,\n",
    "    sandbox_dir=Path(\".data\"),\n",
    "    mount_dir=\"/mnt/data\",\n",
    "    chat_driver_config=ChatDriverConfig(\n",
    "        openai_client=async_client,\n",
    "        model=model,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Register the skill with the assistant.\n",
    "assistant.register_skills([posix_skill])\n",
    "\n",
    "# Chat with the assistant.\n",
    "while True:\n",
    "    message = input(\"User: \")\n",
    "    if message == \"\":\n",
    "        break\n",
    "    print(f\"User: {message}\", flush=True)\n",
    "    response = await assistant.generate_response(message)\n",
    "    print(f\"Assistant: {response}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a routine from a skill in an assistant (non-streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from skill_library import Assistant\n",
    "from chat_driver import ChatDriverConfig\n",
    "from posix_skill import PosixSkill\n",
    "\n",
    "# Define the posix skill. This skill will be used by the assistant. Note that\n",
    "# some skills may have a conversational interface using a chat driver.\n",
    "\n",
    "\n",
    "# Define the assistant.\n",
    "assistant = Assistant(\n",
    "    name=\"Alice\",\n",
    "    chat_driver_config=ChatDriverConfig(\n",
    "        openai_client=async_client,\n",
    "        model=model,\n",
    "        instructions=\"You are a helpful assistant.\",\n",
    "    ),\n",
    "    session_id=\"assistant-123\",\n",
    ")\n",
    "\n",
    "posix_skill = PosixSkill(\n",
    "    context=assistant.context,\n",
    "    sandbox_dir=Path(\".data\"),\n",
    "    mount_dir=\"/mnt/data\",\n",
    "    chat_driver_config=ChatDriverConfig(\n",
    "        openai_client=async_client,\n",
    "        model=model,\n",
    "    ),\n",
    ")\n",
    "\n",
    "assistant.register_skills([posix_skill])\n",
    "\n",
    "# Let's see what we can do directly against the assistant.\n",
    "print(assistant.list_routines())\n",
    "result = assistant.run_routine(\"posix.make_home_dir\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An assistant with a message queue\n",
    "\n",
    "Our assistants also work with the idea of *events* instead of just responses. As the assistant executes actions and routines, a stream of events are generated which can be subscribed to. This makes embedding the assistant in an existing agentic framework easier. For example, we can wrap this assistant in the Semantic Workbench, or in Teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the nest_asyncio patch to allow asyncio calls handling in this Jupyter\n",
    "# notebook cell.\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from pathlib import Path\n",
    "from skill_library import Assistant\n",
    "from chat_driver import ChatDriverConfig\n",
    "from posix_skill import PosixSkill\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Define the assistant.\n",
    "chat_driver_config = ChatDriverConfig(\n",
    "    openai_client=async_client, model=model, instructions=\"You are a helpful assistant.\"\n",
    ")\n",
    "assistant = Assistant(name=\"Alice\", chat_driver_config=chat_driver_config, session_id=\"assistant-123\")\n",
    "\n",
    "# Define the posix skill.\n",
    "posix_skill = PosixSkill(\n",
    "    context=assistant.context,\n",
    "    sandbox_dir=Path(\".data\"),\n",
    "    mount_dir=\"/mnt/data\",\n",
    "    chat_driver_config=ChatDriverConfig(\n",
    "        openai_client=async_client,\n",
    "        model=model,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Register the skill with the assistant.\n",
    "assistant.register_skills([posix_skill])\n",
    "\n",
    "\n",
    "# Function that allows user input in a non-blocking manner.\n",
    "async def user_input_handler() -> None:\n",
    "    while True:\n",
    "        user_input = await asyncio.to_thread(input, \"User: \")\n",
    "        if user_input == \"\":\n",
    "            assistant.stop()\n",
    "            break\n",
    "        print(f\"User: {user_input}\", flush=True)\n",
    "        await assistant.put_message(user_input)\n",
    "\n",
    "\n",
    "# Start the user input in a non-blocking way.\n",
    "input_task = asyncio.create_task(user_input_handler())\n",
    "\n",
    "# Start the assistant.\n",
    "async for event in assistant.events:\n",
    "    print(f\"Assistant: {event.message}\", flush=True)  # type: ignore\n",
    "\n",
    "await assistant.wait()\n",
    "await input_task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
