{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chat Driver\n",
        "\n",
        "An OpenAI Chat Completions API wrapper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook setup\n",
        "\n",
        "Run this cell to set the notebook up. Other sections can be run independently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from azure.identity import aio, DefaultAzureCredential, get_bearer_token_provider, AzureCliCredential\n",
        "\n",
        "from openai import AsyncAzureOpenAI, AzureOpenAI\n",
        "\n",
        "import logging \n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "LOGGING = {\n",
        "    \"version\": 1,\n",
        "    \"disable_existing_loggers\": False,\n",
        "    \"formatters\": {\n",
        "        \"json\": {\n",
        "            \"()\": \"pythonjsonlogger.jsonlogger.JsonFormatter\",\n",
        "            \"fmt\": \"%(asctime)s %(levelname)s %(name)s %(message)s\",\n",
        "\n",
        "        }\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "# Set up structured logging to a file. All of the cells in this notebook use\n",
        "# this logger. Find them at .data/logs.jsonl.\n",
        "class JsonFormatter(logging.Formatter):\n",
        "    def format(self, record) -> str:\n",
        "        record_dict = record.__dict__\n",
        "        log_record = {\n",
        "            'timestamp': self.formatTime(record, self.datefmt),\n",
        "            'level': record.levelname,\n",
        "            'session_id': record_dict.get('session_id', None),\n",
        "            'run_id': record_dict.get('run_id', None),\n",
        "            'message': record.getMessage(),\n",
        "            'data': record_dict.get('data', None),\n",
        "            'module': record.module,\n",
        "            'funcName': record.funcName,\n",
        "            'lineNumber': record.lineno,\n",
        "            'logger': record.name,\n",
        "        }\n",
        "        extra_fields = {\n",
        "            key: value for key, value in record.__dict__.items() \n",
        "            if key not in ['levelname', 'msg', 'args', 'exc_info', 'funcName', 'module', 'lineno', 'name', 'message', 'asctime', 'session_id', 'run_id', 'data']\n",
        "        }\n",
        "        log_record.update(extra_fields)\n",
        "        return json.dumps(log_record)\n",
        "\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "modules = ['httpcore.connection', 'httpcore.http11', 'httpcore.sync.connection', 'httpx', 'openai', 'urllib3.connectionpool', 'urllib3.util.retry']\n",
        "for module in modules:\n",
        "    logging.getLogger(module).setLevel(logging.ERROR)\n",
        "if logger.hasHandlers():\n",
        "    logger.handlers.clear()\n",
        "data_dir = Path('.data')\n",
        "if not data_dir.exists():\n",
        "    data_dir.mkdir()\n",
        "handler = logging.FileHandler(data_dir / 'logs.jsonl')\n",
        "handler.setFormatter(JsonFormatter())\n",
        "logger.addHandler(handler)\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "azure_openai_config = {\n",
        "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\"),\n",
        "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\", \"\"),\n",
        "    \"api_version\": os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"\"),\n",
        "    \"max_retries\": 2,\n",
        "}\n",
        "logger.info(\"Azure OpenAI configuration\", extra=azure_openai_config)\n",
        "\n",
        "async_client = AsyncAzureOpenAI(\n",
        "    **azure_openai_config,\n",
        "    azure_ad_token_provider=aio.get_bearer_token_provider(\n",
        "        aio.AzureCliCredential(),\n",
        "        \"https://cognitiveservices.azure.com/.default\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    **azure_openai_config,\n",
        "    azure_ad_token_provider=get_bearer_token_provider(\n",
        "        AzureCliCredential(),\n",
        "        \"https://cognitiveservices.azure.com/.default\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "model: str = azure_openai_config.get(\"azure_deployment\", \"gpt-4o\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ChatCompletionsAPI usage\n",
        "\n",
        "Azure/OpenAI's Chat Completions API is the fundamental building block of an AI assistant that uses the GPT model. \n",
        "\n",
        "- https://platform.openai.com/docs/api-reference/chat\n",
        "- https://github.com/openai/openai-python/blob/main/api.md\n",
        "- https://platform.openai.com/docs/api-reference/chat drivers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sync"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': 'chatcmpl-AQga9wXFldlhHVce3CfXMQ7jXo9L9', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'This is a test.', 'refusal': None, 'role': 'assistant', 'function_call': None, 'tool_calls': None}}], 'created': 1730923577, 'model': 'gpt-4o-2024-08-06', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_d54531d9eb', 'usage': {'completion_tokens': 5, 'prompt_tokens': 12, 'total_tokens': 17, 'completion_tokens_details': None, 'prompt_tokens_details': None}}\n"
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say this is a test\",\n",
        "        }\n",
        "    ],\n",
        "    model=model,\n",
        ")\n",
        "print(completion.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Async"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletion(id='chatcmpl-AQgaCid05i8dGgUHijQsvPAsMYbv4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This is a test.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1730923580, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_d54531d9eb', usage=CompletionUsage(completion_tokens=5, prompt_tokens=12, total_tokens=17, completion_tokens_details=None, prompt_tokens_details=None))\n"
          ]
        }
      ],
      "source": [
        "message_event = await async_client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say this is a test\",\n",
        "        }\n",
        "    ],\n",
        "    model=model,\n",
        ")\n",
        "print(message_event)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': 'chatcmpl-AQgaEhy4ed19h72VpBu8nJBJE3g3L', 'choices': [{'delta': {'content': '', 'function_call': None, 'refusal': None, 'role': 'assistant', 'tool_calls': None}, 'finish_reason': None, 'index': 0, 'logprobs': None}], 'created': 1730923582, 'model': 'gpt-4o-2024-08-06', 'object': 'chat.completion.chunk', 'service_tier': None, 'system_fingerprint': 'fp_d54531d9eb', 'usage': None}\n",
            "{'id': 'chatcmpl-AQgaEhy4ed19h72VpBu8nJBJE3g3L', 'choices': [{'delta': {'content': 'This', 'function_call': None, 'refusal': None, 'role': None, 'tool_calls': None}, 'finish_reason': None, 'index': 0, 'logprobs': None}], 'created': 1730923582, 'model': 'gpt-4o-2024-08-06', 'object': 'chat.completion.chunk', 'service_tier': None, 'system_fingerprint': 'fp_d54531d9eb', 'usage': None}\n",
            "{'id': 'chatcmpl-AQgaEhy4ed19h72VpBu8nJBJE3g3L', 'choices': [{'delta': {'content': ' is', 'function_call': None, 'refusal': None, 'role': None, 'tool_calls': None}, 'finish_reason': None, 'index': 0, 'logprobs': None}], 'created': 1730923582, 'model': 'gpt-4o-2024-08-06', 'object': 'chat.completion.chunk', 'service_tier': None, 'system_fingerprint': 'fp_d54531d9eb', 'usage': None}\n",
            "{'id': 'chatcmpl-AQgaEhy4ed19h72VpBu8nJBJE3g3L', 'choices': [{'delta': {'content': ' a', 'function_call': None, 'refusal': None, 'role': None, 'tool_calls': None}, 'finish_reason': None, 'index': 0, 'logprobs': None}], 'created': 1730923582, 'model': 'gpt-4o-2024-08-06', 'object': 'chat.completion.chunk', 'service_tier': None, 'system_fingerprint': 'fp_d54531d9eb', 'usage': None}\n",
            "{'id': 'chatcmpl-AQgaEhy4ed19h72VpBu8nJBJE3g3L', 'choices': [{'delta': {'content': ' test', 'function_call': None, 'refusal': None, 'role': None, 'tool_calls': None}, 'finish_reason': None, 'index': 0, 'logprobs': None}], 'created': 1730923582, 'model': 'gpt-4o-2024-08-06', 'object': 'chat.completion.chunk', 'service_tier': None, 'system_fingerprint': 'fp_d54531d9eb', 'usage': None}\n",
            "{'id': 'chatcmpl-AQgaEhy4ed19h72VpBu8nJBJE3g3L', 'choices': [{'delta': {'content': '.', 'function_call': None, 'refusal': None, 'role': None, 'tool_calls': None}, 'finish_reason': None, 'index': 0, 'logprobs': None}], 'created': 1730923582, 'model': 'gpt-4o-2024-08-06', 'object': 'chat.completion.chunk', 'service_tier': None, 'system_fingerprint': 'fp_d54531d9eb', 'usage': None}\n",
            "{'id': 'chatcmpl-AQgaEhy4ed19h72VpBu8nJBJE3g3L', 'choices': [{'delta': {'content': None, 'function_call': None, 'refusal': None, 'role': None, 'tool_calls': None}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None}], 'created': 1730923582, 'model': 'gpt-4o-2024-08-06', 'object': 'chat.completion.chunk', 'service_tier': None, 'system_fingerprint': 'fp_d54531d9eb', 'usage': None}\n"
          ]
        }
      ],
      "source": [
        "stream = await async_client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Say this is a test\",\n",
        "        }\n",
        "    ],\n",
        "    model=model,\n",
        "    stream=True,\n",
        ")\n",
        "async for chunk in stream:\n",
        "    print(chunk.model_dump())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OpenAI Helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Standardized response handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The future of AI is both exciting and complex, with its trajectory shaped by advances in technology, ethical considerations, and societal needs. As we look ahead, several key themes emerge:\n",
            "\n",
            "1. **Integration and Personalization**: AI will become increasingly integrated into our daily lives, driving personalized experiences. From healthcare to education, AI systems will tailor recommendations and interventions to individual needs, optimizing outcomes across various sectors.\n",
            "\n",
            "2. **AI in Healthcare**: We can expect AI to revolutionize the healthcare industry by enhancing diagnostic accuracy, streamlining administrative processes, and developing personalized medicine. AI-driven tools could predict diseases, recommend treatments, and even aid in surgical procedures, ultimately improving patient care and reducing costs.\n",
            "\n",
            "3. **Autonomous Systems**: Autonomous vehicles, drones, and robotic systems will become more prevalent, transforming industries like transportation, logistics, and manufacturing. These systems will improve efficiency and safety while also creating new business models and opportunities.\n",
            "\n",
            "4. **Ethical and Responsible AI**: As AI systems become more autonomous, the demand for ethical AI frameworks will increase. Ensuring transparency, fairness, accountability, and privacy will be crucial to maintaining public trust. Developing AI systems that align with human values and societal norms will be an ongoing challenge.\n",
            "\n",
            "5. **AI and the Workforce**: While AI will automate certain tasks, it will also create new job opportunities and demand an upskilled workforce. It is important to focus on reskilling and education initiatives to prepare the workforce for an AI-augmented future.\n",
            "\n",
            "6. **AI in Climate and Sustainability**: AI will play a significant role in addressing climate change and promoting sustainability. From optimizing energy usage and improving agricultural practices to predicting environmental changes, AI could be a critical tool in creating a more sustainable future.\n",
            "\n",
            "7. **AI in Creativity and Arts**: AI is increasingly being used in creative fields, such as music, art, and literature. While it can augment human creativity by offering new tools and perspectives, there will be ongoing discussions about the nature of creativity and authorship.\n",
            "\n",
            "8. **AI Governance and Policy**: With AI's growing influence, policy and regulation will need to keep pace to address issues such as data ownership, algorithmic bias, and national security. International collaboration may be necessary to create coherent frameworks addressing these challenges.\n",
            "\n",
            "In summary, AI has the potential to greatly benefit society, but its development requires thoughtful consideration of ethical, social, and economic impacts. As we move forward, collaboration among technologists, policymakers, and the public will be essential to harness AI for the greater good.\n"
          ]
        }
      ],
      "source": [
        "from context import Context\n",
        "from openai_client.errors import CompletionError, validate_completion\n",
        "from openai_client.logging import extra_data, serializable_completion_args\n",
        "from openai_client.completion import completion_message_string\n",
        "\n",
        "context = Context(\"conversation-id-1005\")\n",
        "\n",
        "# We use a metadata dictionary in our helpers to store information about the\n",
        "# completion request.\n",
        "metadata = {}\n",
        "\n",
        "# This is just standard OpenAI completion request arguments.\n",
        "completion_args = {\n",
        "    \"model\": model,\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a famous computer scientist. You are giving a talk at a conference. You are talking about the future of AI and how it will change the world. You are asked a questions by audience members and answer thoughtfully.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is the future of AI?\",\n",
        "        }\n",
        "    ],\n",
        "}\n",
        "\n",
        "# If we these completion args to logs and metadata, though, they need to be\n",
        "# serializable. We have a helper for that.\n",
        "metadata[\"completion_args\"] = serializable_completion_args(completion_args)\n",
        "\n",
        "# We have helpers for validating the response and handling exceptions in a\n",
        "# standardized way. These ensure that logging happens and metadata is loaded up\n",
        "# properly.\n",
        "try:\n",
        "    completion = await async_client.beta.chat.completions.parse(**completion_args)\n",
        "\n",
        "    # This helper looks for any error-like situations (the model refuses to\n",
        "    # answer, content filters, incomplete responses) and throws exceptions that\n",
        "    # are handled by the next helper. The first argument is an identifier that\n",
        "    # will be used for logs and metadata namespacing.\n",
        "    validate_completion(completion)\n",
        "    logger.debug(\"completion response.\", extra=extra_data(completion))\n",
        "    metadata[\"completion\"] = completion.model_dump()\n",
        "\n",
        "except Exception as e:\n",
        "    # This helper processes all the types of error conditions you might get from\n",
        "    # the OpenAI API in a standardized way.\n",
        "    completion_error = CompletionError(e)\n",
        "    print(completion_error)\n",
        "    print(completion_error.body)\n",
        "\n",
        "else:\n",
        "    # The message_string helper is used to extract the response from the completion\n",
        "    # (which can get tedious).\n",
        "    print(completion_message_string(completion))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"thoughts\": \"AI is rapidly evolving and has the potential to transform virtually every industry. With advancements in machine learning, natural language processing, and robotics, AI will continue to play a crucial role in automating routine tasks and providing intelligent insights.\",\n",
            "  \"answer\": \"The future of AI involves deeper integration into everyday life and industry. We will likely see AI systems becoming more autonomous, sophisticated, and seamlessly integrated into systems like healthcare, transportation, and personalized services. AI's future encompasses not only technological advancements but also ethical considerations and ensuring beneficial societal impacts.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from context import Context\n",
        "from openai_client.errors import CompletionError, validate_completion\n",
        "from openai_client.logging import extra_data, serializable_completion_args\n",
        "from openai_client.completion import completion_message_dict, JSON_OBJECT_RESPONSE_FORMAT\n",
        "\n",
        "context = Context(\"conversation-id-1002\")\n",
        "metadata = {}\n",
        "completion_args = {\n",
        "    \"model\": model,\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a famous computer scientist. You are giving a talk at a conference. You are talking about the future of AI and how it will change the world. You are asked a questions by audience members and return your answer as valid JSON like { \\\"thoughts\\\": <some thoughts>, \\\"answer\\\": <an answer> }.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is the future of AI?\",\n",
        "        }\n",
        "    ],\n",
        "    \"response_format\": JSON_OBJECT_RESPONSE_FORMAT,\n",
        "}\n",
        "metadata[\"completion_args\"] = serializable_completion_args(completion_args)\n",
        "try:\n",
        "    completion = await async_client.beta.chat.completions.parse(**completion_args)\n",
        "    validate_completion(completion)\n",
        "    metadata[\"completion\"] = completion.model_dump()\n",
        "except Exception as e:\n",
        "    completion_error = CompletionError(e)\n",
        "    metadata[\"completion_error\"] = completion_error.body\n",
        "    logger.error(completion_error.message, extra=extra_data({\"error\": completion_error.body, \"metadata\": metadata}))\n",
        "else:\n",
        "    message = completion_message_dict(completion)\n",
        "    print(json.dumps(message, indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Structured Output\n",
        "\n",
        "Any Pydantic BaseModel can be used as the \"response_format\" and OpenAI will try to load it up for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"thoughts\": \"AI has shown immense potential in various fields, including healthcare, transportation, and climate science. The trajectory of its development suggests even greater integration into daily life and business operations.\",\n",
            "  \"answer\": \"The future of AI lies in its ability to become more autonomous, adaptive, and integrated into various facets of life and industry. We will likely see AI taking on increasingly complex tasks with minimal human intervention, improving efficiency and productivity. It will transform sectors like healthcare through predictive diagnostics, personalize education, and enhance decision-making in businesses with deeper insights from data analytics. However, it will also be crucial to address ethical concerns, such as privacy, bias, and the impact on jobs, to ensure AI serves the broader good.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from context import Context\n",
        "from pydantic import BaseModel\n",
        "from typing import cast\n",
        "from openai_client.errors import CompletionError, validate_completion\n",
        "from openai_client.logging import extra_data, serializable_completion_args\n",
        "from openai_client.completion import completion_message_dict, JSON_OBJECT_RESPONSE_FORMAT\n",
        "\n",
        "class Output(BaseModel):\n",
        "    thoughts: str\n",
        "    answer: str\n",
        "\n",
        "context = Context(\"conversation-id-1002\")\n",
        "metadata = {}\n",
        "completion_args = {\n",
        "    \"model\": model,\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a famous computer scientist. You are giving a talk at a conference. You are talking about the future of AI and how it will change the world. You are asked a questions by audience members and return your answer as valid JSON like { \\\"thoughts\\\": <some thoughts>, \\\"answer\\\": <an answer> }.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is the future of AI?\",\n",
        "        }\n",
        "    ],\n",
        "    \"response_format\": Output,\n",
        "}\n",
        "\n",
        "metadata[\"completion_args\"] = serializable_completion_args(completion_args)\n",
        "try:\n",
        "    completion = await async_client.beta.chat.completions.parse(**completion_args)\n",
        "    validate_completion(completion)\n",
        "    metadata[\"completion\"] = completion.model_dump()\n",
        "except Exception as e:\n",
        "    completion_error = CompletionError(e)\n",
        "    metadata[\"completion_error\"] = completion_error.body\n",
        "    logger.error(completion_error.message, extra=extra_data({\"error\": completion_error.body, \"metadata\": metadata}))\n",
        "else:\n",
        "    # The parsed message is in the `parsed` attribute.\n",
        "    output = cast(Output, completion.choices[0].message.parsed)\n",
        "    print(output.model_dump_json(indent=2))\n",
        "\n",
        "    # Or you can just get the text of the message like usual.\n",
        "    # print(completion.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OpenAI Chat Completion Driver (a.k.a \"chat driver\")\n",
        "\n",
        "### OpenAI Assistants\n",
        "\n",
        "The Azure/OpenAI Assistants API is newer, stateful API that splits an `assistant` from the data about a conversation `thread` that can be `run` against an `assistant`. Additionally, you can add `tools` to an assistant that enable the assistant to have more interactive capabilities. The tools currently available are:\n",
        "\n",
        "- *Functions*: Registering local functions with the assistant so it knows it can call them before generating a response. This is a \"hold on let me look that up for you\" kind of interaction.\n",
        "- *File Search* (formerly the retrieval plugin): Attach one or more files and they will be RAG-vectorized and available as content to the assistant.\n",
        "- *Code Interpreter*: Run python code in a secure sandbox.\n",
        "\n",
        "The Assistant API productized as OpenAI's `GPTs` product. The `GPT Builder` lets developers create and deploy GPTs assistants using a web interface.\n",
        "\n",
        "### Chat Driver\n",
        "\n",
        "But an \"assistant\" requires pretty strong \"abstraction lock-in\". This thing isn't really an assistant in the fullest sense... it's more like a \"pseudo-assistant\", but this confuses things. Let's just let the Chat Completion API be what it is and drive it as necessary as we create our assistants. Let's just wrap up the function calling bits (which, ultimately, can give you the other tools like Functions and File Search) in a simple-to-use GPT-like interface we'll call a *chat driver*.\n",
        "\n",
        "The chat driver is meant to be used the exact way the Chat Completions API is... just easier.\n",
        "\n",
        "Our chat driver provides:\n",
        "\n",
        "- The ability to almost magically register functions to the function tool using a `FunctionRegistry`.\n",
        "- Tracking of message history.\n",
        "- Management of a `Context` object that can be used for session management and supply additional context to functions.\n",
        "- Some prompt creation helpers.\n",
        "- Other utilities... this is just meant to be an interface you can use to forget about all the api complexities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Here is the simplest usage of a chat driver\n",
        "\n",
        "Notice that a .data directory is created by default. This is where the conversation history is stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conversation-id-1000\n",
            "\n",
            "Hello Paul! How can I assist you today?\n",
            "\n",
            "Commands:\n",
            "help(): Return this help message.\n",
            "erase(name: str): Erases a stored value.\n",
            "echo(text: str): Return the text.\n",
            "get_file_contents(file_path: str): Return the contents of a file.\n",
            "\n",
            "conversation-id-1000: Hi, my name is Paul.\n",
            "\n",
            "The content of \"123.txt\" is: \"The purpose of life is to be happy.\"\n",
            "\n",
            "{\n",
            "  \"id\": \"9444f8f2-aa5a-4c19-9bf4-d36b6bfa9ba4\",\n",
            "  \"session_id\": null,\n",
            "  \"timestamp\": \"2024-11-06T20:06:27.777169\",\n",
            "  \"message\": \"The content of \\\"123.txt\\\" is: \\\"The purpose of life is to be happy.\\\"\",\n",
            "  \"metadata\": {\n",
            "    \"completion_args\": {\n",
            "      \"model\": \"gpt-4o\",\n",
            "      \"messages\": [\n",
            "        {\n",
            "          \"role\": \"user\",\n",
            "          \"content\": \"What is the future of AI?\"\n",
            "        },\n",
            "        {\n",
            "          \"role\": \"assistant\",\n",
            "          \"content\": \"The future of AI is incredibly promising and will likely be revolutionary in many aspects of our lives. In the coming years and decades, we can expect several major trends and developments to shape the landscape of artificial intelligence:\\n\\n1. **Ubiquitous Integration**: AI will continue to permeate all aspects of our daily lives, from personal assistants and smart home devices to complex systems in healthcare, finance, and transportation. This integration will enable more efficient, personalized, and automated experiences.\\n\\n2. **Advanced Machine Learning**: We will see significant advancements in machine learning techniques, particularly in areas such as reinforcement learning, unsupervised learning, and transfer learning. These advancements will improve AI's ability to learn from fewer examples and adapt more flexibly to new and changing environments.\\n\\n3. **Ethical and Explainable AI**: As AI becomes more entrenched in critical decision-making processes, there will be a stronger emphasis on developing ethical guidelines and explainable AI systems. This will involve creating transparent models that can be understood and trusted by humans, ensuring fairness and reducing bias.\\n\\n4. **AI and Human Collaboration**: The future will see AI as a collaborator rather than a mere tool. AI systems will augment human abilities, providing insights and recommendations so that people can make better decisions and enhance creativity and productivity across various fields.\\n\\n5. **AI in Healthcare**: AI will play a transformative role in healthcare, enabling early diagnosis, personalized treatment plans, drug discovery, and efficient management of healthcare systems. This can lead to significant improvements in patient outcomes and accessibility to medical services.\\n\\n6. **Autonomous Systems**: The development of autonomous vehicles, drones, and robots will advance, impacting industries such as logistics, agriculture, and urban planning. These systems will greatly improve efficiency and safety in operations.\\n\\n7. **AI Governance and Regulation**: As AI systems grow more powerful, there will be an increasing need for regulation to ensure they are used responsibly and do not harm society. This includes addressing issues such as privacy, security, and the impact on labor markets.\\n\\n8. **AI for Sustainability**: AI will be crucial in addressing global challenges like climate change, resource management, and conservation efforts, optimizing energy use, predicting environmental changes, and developing sustainable practices.\\n\\n9. **Quantum Computing and AI**: The integration of AI with quantum computing holds the potential to solve problems previously considered intractable, speeding up computation and enhancing AI's capabilities.\\n\\n10. **AI and Creativity**: AI will increasingly be involved in creative domains, assisting with tasks such as art, music, and writing, leading to new forms of expression and collaboration between humans and machines.\\n\\nIn summary, while AI presents numerous opportunities, it also comes with challenges that society must address. Ensuring that its development is aligned with societal values will be crucial for leveraging AI's potential in a way that benefits everyone.\"\n",
            "        },\n",
            "        {\n",
            "          \"role\": \"user\",\n",
            "          \"content\": \"What is the future of AI?\"\n",
            "        },\n",
            "        {\n",
            "          \"role\": \"assistant\",\n",
            "          \"content\": \"Hello Paul! How can I assist you today?\"\n",
            "        },\n",
            "        {\n",
            "          \"role\": \"user\",\n",
            "          \"content\": \"Please tell me what's in file 123.txt.\"\n",
            "        }\n",
            "      ],\n",
            "      \"tools\": [\n",
            "        {\n",
            "          \"type\": \"function\",\n",
            "          \"function\": {\n",
            "            \"name\": \"help\",\n",
            "            \"description\": \"Return this help message.\",\n",
            "            \"strict\": true,\n",
            "            \"parameters\": {\n",
            "              \"type\": \"object\",\n",
            "              \"properties\": {},\n",
            "              \"additionalProperties\": false\n",
            "            }\n",
            "          }\n",
            "        },\n",
            "        {\n",
            "          \"type\": \"function\",\n",
            "          \"function\": {\n",
            "            \"name\": \"erase\",\n",
            "            \"description\": \"Erases a stored value.\",\n",
            "            \"strict\": true,\n",
            "            \"parameters\": {\n",
            "              \"type\": \"object\",\n",
            "              \"properties\": {\n",
            "                \"name\": {\n",
            "                  \"type\": \"string\"\n",
            "                }\n",
            "              },\n",
            "              \"additionalProperties\": false,\n",
            "              \"required\": [\n",
            "                \"name\"\n",
            "              ]\n",
            "            }\n",
            "          }\n",
            "        },\n",
            "        {\n",
            "          \"type\": \"function\",\n",
            "          \"function\": {\n",
            "            \"name\": \"echo\",\n",
            "            \"description\": \"Return the text.\",\n",
            "            \"strict\": true,\n",
            "            \"parameters\": {\n",
            "              \"type\": \"object\",\n",
            "              \"properties\": {\n",
            "                \"text\": {\n",
            "                  \"type\": \"string\"\n",
            "                }\n",
            "              },\n",
            "              \"additionalProperties\": false,\n",
            "              \"required\": [\n",
            "                \"text\"\n",
            "              ]\n",
            "            }\n",
            "          }\n",
            "        },\n",
            "        {\n",
            "          \"type\": \"function\",\n",
            "          \"function\": {\n",
            "            \"name\": \"get_file_contents\",\n",
            "            \"description\": \"Return the contents of a file.\",\n",
            "            \"strict\": true,\n",
            "            \"parameters\": {\n",
            "              \"type\": \"object\",\n",
            "              \"properties\": {\n",
            "                \"file_path\": {\n",
            "                  \"type\": \"string\"\n",
            "                }\n",
            "              },\n",
            "              \"additionalProperties\": false,\n",
            "              \"required\": [\n",
            "                \"file_path\"\n",
            "              ]\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      ],\n",
            "      \"tool_choice\": null,\n",
            "      \"response_format\": {\n",
            "        \"type\": \"text\"\n",
            "      }\n",
            "    },\n",
            "    \"completion\": {\n",
            "      \"id\": \"chatcmpl-AQgaIFjYmKV3PUaYNUoYOKQ9LraYg\",\n",
            "      \"choices\": [\n",
            "        {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"index\": 0,\n",
            "          \"logprobs\": null,\n",
            "          \"message\": {\n",
            "            \"content\": \"The future of AI is set to be transformative, with significant advancements and implications across many areas of life and industry. Here are some key trends and developments expected in the future of AI:\\n\\n1. **Widespread Integration**: AI will become deeply embedded into everyday life, enhancing technologies in sectors such as healthcare, finance, education, and entertainment. This integration will facilitate more efficient, personalized, and automated experiences.\\n\\n2. **Advanced Machine Learning**: Continuous improvements in machine learning algorithms, including deep learning, will enable AI systems to process and interpret complex data more effectively. This advancement will help AI systems become more autonomous and capable.\\n\\n3. **Ethical and Fair AI**: As AI's role grows, developing ethical guidelines and ensuring fairness will become increasingly important. Efforts will focus on minimizing bias and increasing transparency, fostering trust and acceptability.\\n\\n4. **Human-AI Collaboration**: AI will increasingly act as a collaborative partner, augmenting human abilities and enhancing creativity, decision-making, and productivity across various fields. This symbiosis will redefine how we work and interact with technology.\\n\\n5. **Healthcare Innovations**: AI is expected to revolutionize healthcare through improved diagnostics, personalized treatments, predictive analytics, and efficient management of healthcare operations. This could lead to better patient outcomes and more accessible healthcare services.\\n\\n6. **Growth of Autonomous Systems**: The development of autonomous vehicles, drones, and robotics will continue to advance, transforming industries like transportation, logistics, and agriculture by improving safety, efficiency, and sustainability.\\n\\n7. **AI for Sustainability**: AI will play a crucial role in tackling environmental challenges, optimizing resource usage, improving climate models, and promoting sustainable practices, thereby contributing to environmental conservation efforts.\\n\\n8. **Quantum Computing and AI**: The synergy between AI and quantum computing could result in unprecedented computational capabilities, leading to significant breakthroughs in fields such as cryptography, complex simulations, and material science.\\n\\n9. **Creative Applications**: AI will increasingly contribute to creative industries, aiding in the production of art, music, and literature, and providing innovative tools and mediums for artistic exploration.\\n\\n10. **Focus on Explainability**: As AI systems become more integral to decision-making, the demand for explainable AI will grow. Developing AI that can clearly articulate its decision-making processes will be crucial for building trust and ensuring accountability.\\n\\nWhile the future of AI offers immense potential, it also poses challenges—including ethical considerations, privacy issues, and potential job displacement. Navigating these challenges will require careful thought, regulation, and collaboration across various stakeholders to ensure that AI benefits society as a whole.\",\n",
            "            \"refusal\": null,\n",
            "            \"role\": \"assistant\",\n",
            "            \"function_call\": null,\n",
            "            \"tool_calls\": [\n",
            "              {\n",
            "                \"id\": \"call_hCAzGLjdWGTBMVbJDi3ZYs2Z\",\n",
            "                \"function\": {\n",
            "                  \"arguments\": \"{\\\"file_path\\\":\\\"123.txt\\\"}\",\n",
            "                  \"name\": \"get_file_contents\",\n",
            "                  \"parsed_arguments\": {\n",
            "                    \"file_path\": \"123.txt\"\n",
            "                  }\n",
            "                },\n",
            "                \"type\": \"function\"\n",
            "              }\n",
            "            ],\n",
            "            \"parsed\": null\n",
            "          }\n",
            "        }\n",
            "      ],\n",
            "      \"created\": 1730923586,\n",
            "      \"model\": \"gpt-4o-2024-08-06\",\n",
            "      \"object\": \"chat.completion\",\n",
            "      \"service_tier\": null,\n",
            "      \"system_fingerprint\": \"fp_d54531d9eb\",\n",
            "      \"usage\": {\n",
            "        \"completion_tokens\": 17,\n",
            "        \"prompt_tokens\": 135,\n",
            "        \"total_tokens\": 152,\n",
            "        \"completion_tokens_details\": null,\n",
            "        \"prompt_tokens_details\": null\n",
            "      }\n",
            "    },\n",
            "    \"tool_completion_args\": {\n",
            "      \"model\": \"gpt-4o\",\n",
            "      \"messages\": [\n",
            "        {\n",
            "          \"role\": \"system\",\n",
            "          \"content\": \"You are a helpful assistant.\"\n",
            "        },\n",
            "        {\n",
            "          \"role\": \"user\",\n",
            "          \"content\": \"Hi, my name is Paul.\"\n",
            "        },\n",
            "        {\n",
            "          \"role\": \"assistant\",\n",
            "          \"content\": \"Hello Paul! How can I assist you today?\"\n",
            "        },\n",
            "        {\n",
            "          \"role\": \"user\",\n",
            "          \"content\": \"Please tell me what's in file 123.txt.\"\n",
            "        },\n",
            "        {\n",
            "          \"role\": \"assistant\",\n",
            "          \"tool_calls\": [\n",
            "            {\n",
            "              \"id\": \"call_hCAzGLjdWGTBMVbJDi3ZYs2Z\",\n",
            "              \"function\": {\n",
            "                \"arguments\": \"{\\\"file_path\\\":\\\"123.txt\\\"}\",\n",
            "                \"name\": \"get_file_contents\",\n",
            "                \"parsed_arguments\": {\n",
            "                  \"file_path\": \"123.txt\"\n",
            "                }\n",
            "              },\n",
            "              \"type\": \"function\"\n",
            "            }\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"role\": \"tool\",\n",
            "          \"content\": \"The purpose of life is to be happy.\",\n",
            "          \"tool_call_id\": \"call_hCAzGLjdWGTBMVbJDi3ZYs2Z\"\n",
            "        }\n",
            "      ],\n",
            "      \"response_format\": {\n",
            "        \"type\": \"text\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from chat_driver import ChatDriver, ChatDriverConfig\n",
        "from context import Context\n",
        "\n",
        "# When an chat driver is created, it will automatically create a context with a\n",
        "# session_id. Or, if you want to use a specific session_id, you can pass it as\n",
        "# an argument. This is useful for scoping this chat driver instance to an\n",
        "# external identifier.\n",
        "context = Context(\"simple-id-1000\")\n",
        "\n",
        "instructions = \"You are a famous computer scientist. You are giving a talk at a conference. You are talking about the future of AI and how it will change the world. You are asked a questions by audience members.\"\n",
        "\n",
        "chat_driver = ChatDriver(\n",
        "    ChatDriverConfig(\n",
        "        openai_client=async_client,\n",
        "        model=model,\n",
        "        instructions=instructions,\n",
        "        context=context,\n",
        "    ),\n",
        ")\n",
        "\n",
        "message_event = await chat_driver.respond(\"What is the future of AI?\")\n",
        "print(message_event.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### You can tell the chat driver to always return JSON\n",
        "\n",
        "Note: You MUST include the word \"JSON\" somewhere in your instructions. This is an OpenAI requirement for JSON return. However, note that a ChatDriver response method only returns string responses in its returned `MessageEvent` since these events are intended to be used in chat scenarios. If you want to transform it into an actual JSON object, you'll need to `json.loads(response.message)` it yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{ \"thoughts\": \"The future of AI is a topic filled with both excitement and caution, as it holds the potential for transformative impacts across various facets of society.\", \"answer\": \"The future of AI is likely to involve increased integration into everyday life, with advancements in areas such as natural language processing, computer vision, and data analysis. AI is set to enhance fields like healthcare through predictive diagnostics, personalized medicine, and robotic surgery. In transportation, autonomous vehicles will likely become more common. AI will also improve efficiencies in industries like manufacturing and logistics. However, this future will also require addressing ethical considerations, data privacy concerns, and ensuring that AI technologies are accessible and beneficial for all members of society. A key focus will be on developing fair and unbiased AI systems, and creating governance frameworks that promote responsible AI development and usage.\" }\n",
            "{\n",
            "  \"thoughts\": \"The future of AI is a topic filled with both excitement and caution, as it holds the potential for transformative impacts across various facets of society.\",\n",
            "  \"answer\": \"The future of AI is likely to involve increased integration into everyday life, with advancements in areas such as natural language processing, computer vision, and data analysis. AI is set to enhance fields like healthcare through predictive diagnostics, personalized medicine, and robotic surgery. In transportation, autonomous vehicles will likely become more common. AI will also improve efficiencies in industries like manufacturing and logistics. However, this future will also require addressing ethical considerations, data privacy concerns, and ensuring that AI technologies are accessible and beneficial for all members of society. A key focus will be on developing fair and unbiased AI systems, and creating governance frameworks that promote responsible AI development and usage.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from chat_driver import ChatDriver, JSON_OBJECT_RESPONSE_FORMAT, ChatDriverConfig\n",
        "from context import Context\n",
        "\n",
        "context = Context(\"conversation-id-1002\")\n",
        "instructions = 'You are a famous computer scientist. You are giving a talk at a conference. You are talking about the future of AI and how it will change the world. You are asked a questions by audience members and return your answer as valid json, like this: { \"thoughts\": <some thoughts>, \"answer\": <an answer> }.'\n",
        "\n",
        "chat_driver = ChatDriver(\n",
        "    ChatDriverConfig(\n",
        "        openai_client=async_client,\n",
        "        model=model,\n",
        "        instructions=instructions,\n",
        "        context=context,\n",
        "    ),\n",
        ")\n",
        "\n",
        "message_event = await chat_driver.respond(\"What is the future of AI?\", response_format=JSON_OBJECT_RESPONSE_FORMAT)\n",
        "print(message_event.message)\n",
        "\n",
        "print(json.dumps(json.loads(message_event.message or \"\"), indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chat drivers can return structured responses\n",
        "\n",
        "Just give it a class that inherits from Pydantic BaseModel and it will return your response in that structure. Most the time, if you want this kind of thing, you probably don't want a Chat Driver. Just use the OpenAI client with the helpers above. However, in the rare case that you want to actually use the structured output to guarantee the response from the model, this is here for you. You'll need to marshal the object yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"thoughts\":\"AI is rapidly advancing and its future holds great potential and considerable responsibility. As AI technologies become more integrated into society, we will see transformations across various sectors, including healthcare, transportation, education, and manufacturing. However, these advancements also come with ethical considerations and the need for responsible development.\",\"answer\":\"The future of AI is both exciting and complex. We will likely see AI becoming more autonomous, improving its ability to understand and interpret nuanced human interactions, and solving complex problems in ways that were previously unimaginable. In healthcare, AI could lead to personalized medicine and better diagnostic tools. In transportation, we'll see more autonomous vehicles that could reshape our cities and daily commutes. However, with these advancements comes the responsibility to address ethical concerns such as privacy, security, and fairness. It's crucial that as AI capabilities grow, we also develop frameworks to guide its ethical use and ensure that its benefits are distributed equitably across society.\"}\n",
            "{\n",
            "  \"thoughts\": \"AI is rapidly advancing and its future holds great potential and considerable responsibility. As AI technologies become more integrated into society, we will see transformations across various sectors, including healthcare, transportation, education, and manufacturing. However, these advancements also come with ethical considerations and the need for responsible development.\",\n",
            "  \"answer\": \"The future of AI is both exciting and complex. We will likely see AI becoming more autonomous, improving its ability to understand and interpret nuanced human interactions, and solving complex problems in ways that were previously unimaginable. In healthcare, AI could lead to personalized medicine and better diagnostic tools. In transportation, we'll see more autonomous vehicles that could reshape our cities and daily commutes. However, with these advancements comes the responsibility to address ethical concerns such as privacy, security, and fairness. It's crucial that as AI capabilities grow, we also develop frameworks to guide its ethical use and ensure that its benefits are distributed equitably across society.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Simple chat driver w/ structured response\n",
        "\n",
        "from typing import cast\n",
        "from chat_driver import ChatDriver, ChatDriverConfig, LocalMessageHistoryProvider\n",
        "from context import Context\n",
        "from pydantic import BaseModel\n",
        "\n",
        "context = Context(\"structured-1000\")\n",
        "\n",
        "instructions = 'You are a famous computer scientist. You are giving a talk at a conference. You are talking about the future of AI and how it will change the world. You are asked a questions by audience members and return a thoughtful response.'\n",
        "\n",
        "class ThoughtfulResponse(BaseModel):\n",
        "    \"\"\"A thoughtful response to a question.\"\"\"\n",
        "    thoughts: str\n",
        "    answer: str\n",
        "\n",
        "chat_driver = ChatDriver(\n",
        "    ChatDriverConfig(\n",
        "        openai_client=async_client,\n",
        "        model=model,\n",
        "        instructions=instructions,\n",
        "        context=context,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Let's clear the data from previous runs.\n",
        "message_provider = cast(LocalMessageHistoryProvider, chat_driver.message_provider)\n",
        "message_provider.delete_all()\n",
        "\n",
        "message_event = await chat_driver.respond(\"What is the future of AI?\", response_format=ThoughtfulResponse)\n",
        "\n",
        "# As always, the event will come back with a string message.\n",
        "print(message_event.message)\n",
        "\n",
        "# If you really want to, you can turn the JSON string back into a Pydantic model.\n",
        "thoughtful_response = ThoughtfulResponse(**json.loads(message_event.message or \"\"))\n",
        "print(thoughtful_response.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### You can register functions to chat drivers\n",
        "\n",
        "Chat drivers will use any functions you give it as both OpenAI tool calls, and as commands.\n",
        "\n",
        "With each response call, you can specify what type of response you want to have... string, dictionary, or Pydantic model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conversation-id-1002\n",
            "\n",
            "Hello Paul! How can I assist you today?\n",
            "\n",
            "Commands:\n",
            "help(): Return this help message.\n",
            "erase(name: str): Erases a stored value.\n",
            "json_thing(): Return json.\n",
            "get_weather(input: Input): Return the weather.\n",
            "echo(text: str): Return the text.\n",
            "get_file_contents(file_path: str): Return the contents of a file.\n",
            "\n",
            "Args:\n",
            "- file_path: The path to the file.\n",
            "\n",
            "conversation-id-1002: Echo this.\n",
            "\n",
            "The content of \"123.txt\" is: \"The purpose of life is to be happy.\"\n",
            "\n",
            "{\"description\":\"Sunny\",\"cloud_cover\":0.2,\"temp_c\":25.0,\"temp_f\":77.0}\n"
          ]
        }
      ],
      "source": [
        "from typing import Any, cast\n",
        "from chat_driver import ChatDriver, ChatDriverConfig\n",
        "from context import Context, ContextProtocol\n",
        "from chat_driver import LocalMessageHistoryProvider\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "# When an chat driver is created, it will automatically create a context with a\n",
        "# session_id. Or, if you want to use a specific session_id, you can pass it as\n",
        "# an argument. This is useful for scoping this chat driver instance to an\n",
        "# external identifier.\n",
        "context = Context(\"conversation-id-1002\")\n",
        "\n",
        "\n",
        "# Define tool functions for the chat driver. All functions used by the chat driver\n",
        "# require a session_id as the first argument.\n",
        "def get_file_contents(context: Context, file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Return the contents of a file.\n",
        "\n",
        "    Args:\n",
        "    - file_path: The path to the file.\n",
        "    \"\"\"\n",
        "    return \"The purpose of life is to be happy.\"\n",
        "\n",
        "\n",
        "def erase(context: Context, name: str) -> str:\n",
        "    \"\"\"Erases a stored value.\"\"\"\n",
        "    return f\"{context.session_id}: {name} erased\"\n",
        "\n",
        "def json_thing(context: Context) -> dict[str, Any]:\n",
        "    \"\"\"Return json.\"\"\"\n",
        "    return {\"key\": \"value\"}\n",
        "\n",
        "class Input(BaseModel):\n",
        "    zipcode: str\n",
        "\n",
        "class Weather(BaseModel):\n",
        "    description: str = Field(description=\"The weather description.\")\n",
        "    cloud_cover: float\n",
        "    temp_c: float\n",
        "    temp_f: float\n",
        "\n",
        "def get_weather(context: Context, input: Input) -> Weather:\n",
        "    \"\"\"Return the weather.\"\"\"\n",
        "    return Weather(description=\"Sunny\", cloud_cover=0.2, temp_c=25.0, temp_f=77.0)\n",
        "\n",
        "# Define the chat driver.\n",
        "instructions = \"You are a helpful assistant.\"\n",
        "\n",
        "# Define the conversation so far (optional).\n",
        "# messages: List[ChatCompletionMessageParam] = []\n",
        "# localMessageHistoryConfig = LocalMessageHistoryProviderConfig(f\"./data/{context.session_id}\", messages)\n",
        "# message_provider = LocalMessageHistoryProvider(localMessageHistoryConfig)\n",
        "\n",
        "chat_driver = ChatDriver(\n",
        "    ChatDriverConfig(\n",
        "        openai_client=async_client,\n",
        "        model=model,\n",
        "        instructions=instructions,\n",
        "        context=context,\n",
        "        # message_provider=message_provider,\n",
        "        commands=[erase, json_thing, get_weather],  # Commands can be registered when instantiating the chat driver.\n",
        "        functions=[erase, json_thing, get_weather],  # Functions can be registered when instantiating the chat driver.\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Let's clear the data from previous runs.\n",
        "message_provider = cast(LocalMessageHistoryProvider, chat_driver.message_provider)\n",
        "message_provider.delete_all()\n",
        "\n",
        "\n",
        "# You can also use the `register_function` decorator to register a function.\n",
        "# Remember, all functions used by the chat driver require a session_id as the\n",
        "# first argument.\n",
        "@chat_driver.register_function_and_command\n",
        "def echo(context: ContextProtocol, text: str) -> str:\n",
        "    \"\"\"Return the text.\"\"\"\n",
        "    return f\"{context.session_id}: {text}\"\n",
        "\n",
        "\n",
        "# You can also register functions manually.\n",
        "chat_driver.register_function_and_command(get_file_contents)\n",
        "\n",
        "# Ok. Let's see if we got one.\n",
        "print(chat_driver.context.session_id)\n",
        "\n",
        "# Let's see if the agent can respond.\n",
        "message_event = await chat_driver.respond(\"Hi, my name is Paul.\")\n",
        "print()\n",
        "print(message_event.message)\n",
        "\n",
        "# Help command (shows command available).\n",
        "message_event = await chat_driver.respond(\"/help\")\n",
        "print()\n",
        "print(message_event.message)\n",
        "\n",
        "# We can run any function or command directly.\n",
        "message_event = await chat_driver.functions.echo(\"Echo this.\")\n",
        "print()\n",
        "print(message_event)\n",
        "\n",
        "# Let's see if the chat driver has the ability to run it's own registered function.\n",
        "message_event = await chat_driver.respond(\"Please tell me what's in file 123.txt.\")\n",
        "print()\n",
        "print(message_event.message)\n",
        "\n",
        "# Stuctured output.\n",
        "message_event = await chat_driver.respond(\"What is the weather in 90210?\", response_format=Weather)\n",
        "print()\n",
        "print(message_event.message)\n",
        "\n",
        "# Let's see the full response event.\n",
        "# print()\n",
        "# print(response.to_json())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chat with a chat driver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: /echo(\"hello world\")\n",
            "Assistant: hello world\n"
          ]
        }
      ],
      "source": [
        "from chat_driver import ChatDriverConfig, ChatDriver\n",
        "from context import Context\n",
        "\n",
        "context = Context(\"conversation-id-1006\")\n",
        "\n",
        "\n",
        "def get_file_contents(context: Context, file_path: str) -> str:\n",
        "    \"\"\"Returns the contents of a file.\"\"\"\n",
        "    return \"The purpose of life is to be happy.\"\n",
        "\n",
        "\n",
        "def erase(context: Context, name: str) -> str:\n",
        "    \"\"\"Erases a stored value.\"\"\"\n",
        "    return f\"{context.session_id}: {name} erased\"\n",
        "\n",
        "\n",
        "def echo(context: Context, value: Any) -> str:  # noqa: F811\n",
        "    \"\"\"Echos a value as a string.\"\"\"\n",
        "    match value:\n",
        "        case str():\n",
        "            return value\n",
        "        case list():\n",
        "            return \", \".join(map(str, value))\n",
        "        case dict():\n",
        "            return json.dumps(value)\n",
        "        case int() | bool() | float():\n",
        "            return str(value)\n",
        "        case _:\n",
        "            return str(value)\n",
        "\n",
        "\n",
        "functions = [get_file_contents, erase, echo]\n",
        "\n",
        "# Define the chat driver.\n",
        "chat_driver_config = ChatDriverConfig(\n",
        "    openai_client=async_client,\n",
        "    model=model,\n",
        "    instructions=\"You are an assistant that has access to a sand-boxed Posix shell.\",\n",
        "    context=context,\n",
        "    commands=functions,\n",
        "    functions=functions,\n",
        ")\n",
        "\n",
        "chat_driver = ChatDriver(chat_driver_config)\n",
        "\n",
        "# Note: Look in the .data directory for the logs, message history, and other data.\n",
        "\n",
        "# Chat with the skill.\n",
        "while True:\n",
        "    message = input(\"User: \")\n",
        "    if message == \"\":\n",
        "        break\n",
        "    print(f\"User: {message}\", flush=True)\n",
        "    message_event = await chat_driver.respond(message)\n",
        "    if message_event.metadata.get(\"error\"):\n",
        "        print(f\"Error: {message_event.metadata.get('error')}\")\n",
        "        print(message_event.to_json())\n",
        "        continue\n",
        "    # You can print the entire message event! \n",
        "    # print(response.to_json())\n",
        "    print(f\"Assistant: {message_event.message}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chat Driver with an Assistant Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from typing import Any, BinaryIO\n",
        "from chat_driver import ChatDriverConfig, ChatDriver, ChatDriverConfig\n",
        "from context import Context\n",
        "from assistant_drive import Drive, DriveConfig, IfDriveFileExistsBehavior \n",
        "\n",
        "session_id = \"conversation-id-1001\"\n",
        "\n",
        "context = Context(session_id)\n",
        "\n",
        "def get_drive_from_context(context):\n",
        "    return Drive(DriveConfig(root=f\".data/drive/{context.session_id}\"))\n",
        "\n",
        "def write_file_contents(context: Context, file_path: str, contents: str) -> str:\n",
        "    \"\"\"Writes the contents to a file.\"\"\"\n",
        "    drive = get_drive_from_context(context)\n",
        "    content_bytes: BinaryIO = BytesIO(contents.encode(\"utf-8\"))\n",
        "    drive.write(content_bytes, file_path, if_exists=IfDriveFileExistsBehavior.OVERWRITE)\n",
        "    return f\"{file_path} updated.\"\n",
        "\n",
        "def read_file_contents(context: Context, file_path: str) -> str:\n",
        "    \"\"\"Returns the contents of a file.\"\"\"\n",
        "    drive = get_drive_from_context(context)\n",
        "    with drive.open_file(file_path) as file:\n",
        "        return file.read().decode(\"utf-8\")\n",
        "\n",
        "functions = [write_file_contents, read_file_contents]\n",
        "\n",
        "# Define the chat driver.\n",
        "chat_driver_config = ChatDriverConfig(\n",
        "    openai_client=async_client,\n",
        "    model=model,\n",
        "    instructions=\"You are an assistant that has access to a sand-boxed Posix shell.\",\n",
        "    context=context,\n",
        "    commands=functions,\n",
        "    functions=functions,\n",
        ")\n",
        "\n",
        "chat_driver = ChatDriver(chat_driver_config)\n",
        "\n",
        "# Note: Look in the .data directory for the logs, message history, and other data.\n",
        "\n",
        "# Chat with the skill.\n",
        "while True:\n",
        "    message = input(\"User: \")\n",
        "    if message == \"\":\n",
        "        break\n",
        "    print(f\"User: {message}\", flush=True)\n",
        "    message_event = await chat_driver.respond(message)\n",
        "    # You can print the entire response event! \n",
        "    # print(response.to_json())\n",
        "    print(f\"Assistant: {message_event.message}\", flush=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
